{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Basic_NeuralNetwork_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEkngCN6TzX6"
      },
      "source": [
        "### Classification Problem: Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Ldk8dWTzX6",
        "outputId": "a812c8d1-f39c-4db2-8f51-0b4ac83c4a2b"
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "# Convert to numpy - Classification\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
        "dummies = pd.get_dummies(df['species']) # Classification\n",
        "species = dummies.columns\n",
        "y = dummies.values\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
        "model.add(Dense(25, activation='relu')) # Hidden 2\n",
        "model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(x,y,verbose=2,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150 samples\n",
            "Epoch 1/100\n",
            "150/150 - 0s - loss: 1.1343\n",
            "Epoch 2/100\n",
            "150/150 - 0s - loss: 1.0067\n",
            "Epoch 3/100\n",
            "150/150 - 0s - loss: 0.9150\n",
            "Epoch 4/100\n",
            "150/150 - 0s - loss: 0.8430\n",
            "Epoch 5/100\n",
            "150/150 - 0s - loss: 0.7892\n",
            "Epoch 6/100\n",
            "150/150 - 0s - loss: 0.7348\n",
            "Epoch 7/100\n",
            "150/150 - 0s - loss: 0.6847\n",
            "Epoch 8/100\n",
            "150/150 - 0s - loss: 0.6382\n",
            "Epoch 9/100\n",
            "150/150 - 0s - loss: 0.6041\n",
            "Epoch 10/100\n",
            "150/150 - 0s - loss: 0.5686\n",
            "Epoch 11/100\n",
            "150/150 - 0s - loss: 0.5374\n",
            "Epoch 12/100\n",
            "150/150 - 0s - loss: 0.5166\n",
            "Epoch 13/100\n",
            "150/150 - 0s - loss: 0.4913\n",
            "Epoch 14/100\n",
            "150/150 - 0s - loss: 0.4706\n",
            "Epoch 15/100\n",
            "150/150 - 0s - loss: 0.4519\n",
            "Epoch 16/100\n",
            "150/150 - 0s - loss: 0.4337\n",
            "Epoch 17/100\n",
            "150/150 - 0s - loss: 0.4207\n",
            "Epoch 18/100\n",
            "150/150 - 0s - loss: 0.4026\n",
            "Epoch 19/100\n",
            "150/150 - 0s - loss: 0.3894\n",
            "Epoch 20/100\n",
            "150/150 - 0s - loss: 0.3764\n",
            "Epoch 21/100\n",
            "150/150 - 0s - loss: 0.3630\n",
            "Epoch 22/100\n",
            "150/150 - 0s - loss: 0.3527\n",
            "Epoch 23/100\n",
            "150/150 - 0s - loss: 0.3409\n",
            "Epoch 24/100\n",
            "150/150 - 0s - loss: 0.3296\n",
            "Epoch 25/100\n",
            "150/150 - 0s - loss: 0.3179\n",
            "Epoch 26/100\n",
            "150/150 - 0s - loss: 0.3091\n",
            "Epoch 27/100\n",
            "150/150 - 0s - loss: 0.2985\n",
            "Epoch 28/100\n",
            "150/150 - 0s - loss: 0.2884\n",
            "Epoch 29/100\n",
            "150/150 - 0s - loss: 0.2825\n",
            "Epoch 30/100\n",
            "150/150 - 0s - loss: 0.2703\n",
            "Epoch 31/100\n",
            "150/150 - 0s - loss: 0.2643\n",
            "Epoch 32/100\n",
            "150/150 - 0s - loss: 0.2554\n",
            "Epoch 33/100\n",
            "150/150 - 0s - loss: 0.2482\n",
            "Epoch 34/100\n",
            "150/150 - 0s - loss: 0.2395\n",
            "Epoch 35/100\n",
            "150/150 - 0s - loss: 0.2341\n",
            "Epoch 36/100\n",
            "150/150 - 0s - loss: 0.2358\n",
            "Epoch 37/100\n",
            "150/150 - 0s - loss: 0.2174\n",
            "Epoch 38/100\n",
            "150/150 - 0s - loss: 0.2181\n",
            "Epoch 39/100\n",
            "150/150 - 0s - loss: 0.2091\n",
            "Epoch 40/100\n",
            "150/150 - 0s - loss: 0.2036\n",
            "Epoch 41/100\n",
            "150/150 - 0s - loss: 0.1967\n",
            "Epoch 42/100\n",
            "150/150 - 0s - loss: 0.1946\n",
            "Epoch 43/100\n",
            "150/150 - 0s - loss: 0.1917\n",
            "Epoch 44/100\n",
            "150/150 - 0s - loss: 0.1816\n",
            "Epoch 45/100\n",
            "150/150 - 0s - loss: 0.1884\n",
            "Epoch 46/100\n",
            "150/150 - 0s - loss: 0.1736\n",
            "Epoch 47/100\n",
            "150/150 - 0s - loss: 0.1745\n",
            "Epoch 48/100\n",
            "150/150 - 0s - loss: 0.1655\n",
            "Epoch 49/100\n",
            "150/150 - 0s - loss: 0.1620\n",
            "Epoch 50/100\n",
            "150/150 - 0s - loss: 0.1579\n",
            "Epoch 51/100\n",
            "150/150 - 0s - loss: 0.1552\n",
            "Epoch 52/100\n",
            "150/150 - 0s - loss: 0.1511\n",
            "Epoch 53/100\n",
            "150/150 - 0s - loss: 0.1493\n",
            "Epoch 54/100\n",
            "150/150 - 0s - loss: 0.1457\n",
            "Epoch 55/100\n",
            "150/150 - 0s - loss: 0.1434\n",
            "Epoch 56/100\n",
            "150/150 - 0s - loss: 0.1426\n",
            "Epoch 57/100\n",
            "150/150 - 0s - loss: 0.1396\n",
            "Epoch 58/100\n",
            "150/150 - 0s - loss: 0.1402\n",
            "Epoch 59/100\n",
            "150/150 - 0s - loss: 0.1320\n",
            "Epoch 60/100\n",
            "150/150 - 0s - loss: 0.1310\n",
            "Epoch 61/100\n",
            "150/150 - 0s - loss: 0.1279\n",
            "Epoch 62/100\n",
            "150/150 - 0s - loss: 0.1290\n",
            "Epoch 63/100\n",
            "150/150 - 0s - loss: 0.1237\n",
            "Epoch 64/100\n",
            "150/150 - 0s - loss: 0.1224\n",
            "Epoch 65/100\n",
            "150/150 - 0s - loss: 0.1197\n",
            "Epoch 66/100\n",
            "150/150 - 0s - loss: 0.1192\n",
            "Epoch 67/100\n",
            "150/150 - 0s - loss: 0.1155\n",
            "Epoch 68/100\n",
            "150/150 - 0s - loss: 0.1175\n",
            "Epoch 69/100\n",
            "150/150 - 0s - loss: 0.1135\n",
            "Epoch 70/100\n",
            "150/150 - 0s - loss: 0.1146\n",
            "Epoch 71/100\n",
            "150/150 - 0s - loss: 0.1092\n",
            "Epoch 72/100\n",
            "150/150 - 0s - loss: 0.1090\n",
            "Epoch 73/100\n",
            "150/150 - 0s - loss: 0.1076\n",
            "Epoch 74/100\n",
            "150/150 - 0s - loss: 0.1044\n",
            "Epoch 75/100\n",
            "150/150 - 0s - loss: 0.1061\n",
            "Epoch 76/100\n",
            "150/150 - 0s - loss: 0.1021\n",
            "Epoch 77/100\n",
            "150/150 - 0s - loss: 0.1029\n",
            "Epoch 78/100\n",
            "150/150 - 0s - loss: 0.1022\n",
            "Epoch 79/100\n",
            "150/150 - 0s - loss: 0.0997\n",
            "Epoch 80/100\n",
            "150/150 - 0s - loss: 0.0989\n",
            "Epoch 81/100\n",
            "150/150 - 0s - loss: 0.0977\n",
            "Epoch 82/100\n",
            "150/150 - 0s - loss: 0.1010\n",
            "Epoch 83/100\n",
            "150/150 - 0s - loss: 0.0966\n",
            "Epoch 84/100\n",
            "150/150 - 0s - loss: 0.0953\n",
            "Epoch 85/100\n",
            "150/150 - 0s - loss: 0.0937\n",
            "Epoch 86/100\n",
            "150/150 - 0s - loss: 0.0965\n",
            "Epoch 87/100\n",
            "150/150 - 0s - loss: 0.0918\n",
            "Epoch 88/100\n",
            "150/150 - 0s - loss: 0.0923\n",
            "Epoch 89/100\n",
            "150/150 - 0s - loss: 0.0900\n",
            "Epoch 90/100\n",
            "150/150 - 0s - loss: 0.0897\n",
            "Epoch 91/100\n",
            "150/150 - 0s - loss: 0.0913\n",
            "Epoch 92/100\n",
            "150/150 - 0s - loss: 0.0871\n",
            "Epoch 93/100\n",
            "150/150 - 0s - loss: 0.0900\n",
            "Epoch 94/100\n",
            "150/150 - 0s - loss: 0.0882\n",
            "Epoch 95/100\n",
            "150/150 - 0s - loss: 0.0867\n",
            "Epoch 96/100\n",
            "150/150 - 0s - loss: 0.0854\n",
            "Epoch 97/100\n",
            "150/150 - 0s - loss: 0.0847\n",
            "Epoch 98/100\n",
            "150/150 - 0s - loss: 0.0840\n",
            "Epoch 99/100\n",
            "150/150 - 0s - loss: 0.0852\n",
            "Epoch 100/100\n",
            "150/150 - 0s - loss: 0.0871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x275f1d9bdc8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC-bCSycTzX9",
        "outputId": "423d9719-8e38-40c1-840f-b85af9386d76"
      },
      "source": [
        "# Print out number of species found:\n",
        "print(species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjOHNCwoTzX_",
        "outputId": "f851d8fe-5f17-4982-ac70-802cbca84f70"
      },
      "source": [
        "pred = model.predict(x)\n",
        "print(f\"Shape: {pred.shape}\")\n",
        "print(pred[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (150, 3)\n",
            "[[9.98257935e-01 1.74211117e-03 1.47250105e-08]\n",
            " [9.94762123e-01 5.23775769e-03 9.35751956e-08]\n",
            " [9.97034669e-01 2.96533993e-03 5.68744980e-08]\n",
            " [9.94459629e-01 5.54029271e-03 1.55113412e-07]\n",
            " [9.98531222e-01 1.46873493e-03 1.33291875e-08]\n",
            " [9.98098075e-01 1.90198515e-03 1.37531018e-08]\n",
            " [9.96991158e-01 3.00874189e-03 7.64488419e-08]\n",
            " [9.97346044e-01 2.65395525e-03 3.05425694e-08]\n",
            " [9.92665589e-01 7.33401440e-03 3.12981911e-07]\n",
            " [9.95905280e-01 4.09475202e-03 5.66798697e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br0VhxQWTzYC"
      },
      "source": [
        "If you would like to turn of scientific notation, the following line can be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS8YhFkuTzYC"
      },
      "source": [
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isRKHISnTzYF"
      },
      "source": [
        "Now we see these values rounded up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQy3q4MvTzYF",
        "outputId": "426ea526-7ca5-4d8f-e8e8-c4af08d02214"
      },
      "source": [
        "print(y[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_uHYW3RTzYI",
        "outputId": "c84343b4-05d9-44fc-aae0-ae32d5d48f51"
      },
      "source": [
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y,axis=1)\n",
        "print(f\"Predictions: {predict_classes}\")\n",
        "print(f\"Expected: {expected_classes}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "Expected: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjM_s1h5TzYL",
        "outputId": "3293f9c4-16e1-48be-e7e1-12295ab5a347"
      },
      "source": [
        "print(species[predict_classes[1:10]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
            "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
            "       'Iris-setosa'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTdjoPGATzYN",
        "outputId": "8eb0e7b2-7f6b-492b-dd1b-83a1b9023db8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "correct = accuracy_score(expected_classes,predict_classes)\n",
        "print(f\"Accuracy: {correct}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9733333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ADll9loTzYP"
      },
      "source": [
        "The code below performs two ad hoc predictions.  The first prediction is simply a single iris flower, and the second predicts two iris flowers.  Notice that the argmax in the second prediction requires **axis=1**?  Since we have a 2D array now, we must specify which axis to take the argmax over.  The value **axis=1** specifies we want the max column index for each row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhllAyaRTzYQ",
        "outputId": "22dbf0c8-db9b-48e7-ed3c-2e333bf7b428"
      },
      "source": [
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)\n",
        "pred = np.argmax(pred)\n",
        "print(f\"Predict that {sample_flower} is: {species[pred]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00208851 0.19842853 0.799483  ]]\n",
            "Predict that [[5. 3. 4. 2.]] is: Iris-virginica\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV_cDsQTzYT",
        "outputId": "1b882b73-a06f-4965-be30-9290f26c4964"
      },
      "source": [
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]],\\\n",
        "        dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "print(f\"Predict that these two flowers {sample_flower} \")\n",
        "print(f\"are: {species[pred]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00208851 0.19842838 0.79948306]\n",
            " [0.9900221  0.00997756 0.00000035]]\n",
            "Predict that these two flowers [[5.  3.  4.  2. ]\n",
            " [5.2 3.5 1.5 0.8]] \n",
            "are: Index(['Iris-virginica', 'Iris-setosa'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ENiqtYTzYW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}